{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_rag.chat.chat_openai import ChatOpenAI\n",
    "from simple_rag.utils import connect_to_database, insert_to_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Successfully Get Access Database\n"
     ]
    }
   ],
   "source": [
    "collection = connect_to_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Large Language Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 1: System's prompt take a short instruct from user's prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Successfully Log Request to Database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'request_id': 'chatcmpl-9sPcmQGIQ0wcBI1NS3Zfz8QoeDYOI',\n",
       " 'output': {'description': ['A fluffy British Shorthair cat lounges on a cozy window sill, gazing outside.',\n",
       "   'Its round face and large, expressive eyes give off a sweet and gentle expression.',\n",
       "   \"The cat's dense, plush coat in a solid color exudes a luxurious and elegant look.\",\n",
       "   \"Sunlight filters through the window, casting a warm glow on the cat's adorable features.\"]},\n",
       " 'completion_tokens': 82,\n",
       " 'prompt_tokens': 217,\n",
       " 'total_tokens': 299}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You possess in-depth knowledge of natural images and can describe them with ease. \\\n",
    "    From the given input text indicating the category name of a certain object, your task involves the following steps:\n",
    "    1-Imagine a scene containing the input object.\n",
    "    2-Generate 4 descriptions about different key appearance features of the input object from the imagined scene, with each description having a maximum of 16 words.\n",
    "    3-Output a JSON object containing the following key:\n",
    "        \"description\": <list of 4 descriptions>\n",
    "\n",
    "    Use the following examples:\n",
    "        Input text: \"sea lion\"\n",
    "        Answer: \"description\": [\"A round-bellied seal sits on a rock, looking intently at something off-camera.\", \"The seal lies with flippers tucked, sleek body well-maintained.\", \"The seal's thick, smooth fur and large dark eyes show alertness and curiosity.\", \"Turquoise water contrasts with the seal's brown fur and grey rock, highlighting its natural environment.\"]\n",
    "\"\"\"\n",
    "response = llm.request(system_prompt=system_prompt, user_prompt=\"British shorthair\")\n",
    "insert_to_db(collection=collection, data=response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 2: System's prompt take a long instruct from user's prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¾ Warning: Failed to refine the output of LLM because: Extra data: line 1 column 2 (char 1)\n",
      "ðŸ”¥ Successfully Log Request to Database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'request_id': 'chatcmpl-9sPcokZQUIkrR8bSS2pdj4YPQSzPK',\n",
       " 'output': '1. This answer is not good for the given instruction because:\\n- Helpfulness: The answer is not as helpful as it could be because it does not effectively simplify the sentence or provide a clearer alternative.\\n- Relevance: The answer does not directly address the need to rewrite the sentence to make it clearer and concise.\\n- Accuracy: The answer does not accurately assess the issues with the original sentence and does not provide a suitable revision.\\n- Level of Details: The answer lacks specific details on how to improve the sentence, making it less informative.\\n- Structure: The answer does not follow a structured approach to breaking down the original sentence and simplifying it effectively.\\n\\n2. [Better Answer] If you have any questions about my rate or need to adjust the scope of this project, please inform me promptly. [End]',\n",
       " 'completion_tokens': 164,\n",
       " 'prompt_tokens': 237,\n",
       " 'total_tokens': 401}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_sample = {\n",
    "    \"id\": \"user_oriented_task_0\",\n",
    "    \"motivation_app\": \"Grammarly\",\n",
    "    \"instruction\": \"The sentence you are given might be too wordy, complicated, or unclear. Rewrite the sentence and make your writing clearer by keeping it concise. Whenever possible, break complex sentences into multiple sentences and eliminate unnecessary words.\",\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"input\": \"If you have any questions about my rate or if you find it necessary to increase or decrease the scope for this project, please let me know.\",\n",
    "            \"output\": \"If you have any questions about my rate or find it necessary to increase or decrease this project's scope, please let me know.\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "def gen_prompt_no_input(ins, outp):\n",
    "\n",
    "    sys_prompt = \"You are a helpful, precise but picky assistant for checking the quality of the answer to a given instruction.\"\n",
    "    prompt_template = \"[Instruction]\\n{ins}\\n\\n[The Start of Answer]\\n{outp}\\n\\n[The End of Answer]\\n\\n[System]\\n{criteria}\\n\\n\"\n",
    "    criteria = (\n",
    "        \"We would like you to answer several questions related to the quality of the answer to the given instruction. \\n\"\n",
    "        + \"1. Why this answer is not good for the given instruction? Analyse based on the Helpfulness, Relevance, Accuracy, Level of Details, and Structure. \\n\"\n",
    "        + \"2. Based on the reason you provided, please generate a better answer while preserving the same content. To achieve that, you may want to adjust the level of details, add bullet points, or use comprehensive words, etc. The answer should be in the format of [Better Answer] your answer [End] \\n\"\n",
    "    )\n",
    "    prompt = prompt_template.format(ins=ins, outp=outp, criteria=criteria)\n",
    "    return sys_prompt, prompt\n",
    "system_prompt, user_prompt = gen_prompt_no_input(ins=structured_sample[\"instruction\"], outp=structured_sample[\"instances\"][0][\"output\"])\n",
    "response = llm.request(system_prompt=system_prompt, user_prompt=user_prompt, max_tokens=2048)\n",
    "insert_to_db(collection=collection, data=response)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
